from langchain_openai import ChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain import hub
import os
from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader

load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    raise EnvironmentError("âŒ OPENAI_API_KEY bulunamadÄ±. .env dosyanÄ±zÄ± kontrol edin.")

file_path = r"C:\Users\fb\Desktop\05-llm\ML 00 Makine OÌˆgÌ†renmesi GirisÌ§.pdf"
if not os.path.exists(file_path):
    raise FileNotFoundError(f"âŒ PDF dosyasÄ± bulunamadÄ±: {file_path}")
loader = PyPDFLoader(file_path)
documents = loader.load()

splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
texts = splitter.split_documents(documents)

mbedding_model = OpenAIEmbeddings(openai_api_key=openai_api_key)
db = FAISS.from_documents(texts, mbedding_model)

llm = ChatOpenAI(model_name="gpt-4", temperature=0.7, openai_api_key=openai_api_key)
retriever = db.as_retriever()
qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)

memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
konular = {
    "Makine Ã¶ÄŸrenmesi nedir": "Makine Ã¶ÄŸrenmesi nedir",
    "Makine Ã¶ÄŸrenmesi uygulama adÄ±mlarÄ±": "Makine Ã¶ÄŸrenmesi uygulama adÄ±mlarÄ±",
    "Makine Ã¶ÄŸrenmesi tÃ¼rleri": "Makine Ã¶ÄŸrenmesi tÃ¼rleri",
    "Makine Ã¶ÄŸrenmesinde performans parametreleri": "Makine Ã¶ÄŸrenmesinde performans parametreleri"
}
print("ğŸ“ ML Mentor AsistanÄ± BaÅŸladÄ± (Ã‡Ä±kmak iÃ§in 'Ã§Ä±k' yazÄ±n)\n")
ogrenilen_konular = set()

while True:
    user_input = input("ğŸ‘¤ Siz: ")
    if user_input.lower() in ["Ã§Ä±k", "exit"]:
        print("GÃ¶rÃ¼ÅŸmek Ã¼zere!")
        break
    
    if "bugÃ¼n ne Ã¶ÄŸrendim" in user_input.lower() or "geri bildirim" in user_input.lower():
        print("\n Asistan (Geri Bildirim):")
        
        if ogrenilen_konular:
            print("BugÃ¼n Ã¶ÄŸrendiÄŸiniz konular:")
            for konu in ogrenilen_konular:
                print(f"- {konu}")
        else: 
            print("- HenÃ¼z bir konu Ã¼zerinde konuÅŸmadÄ±k.")
        eksik_konular = set(konular.values()) - ogrenilen_konular
        if eksik_konular:
            print("\nEksik Kalan Konular:")
            for konu in eksik_konular:
                print(f"- {konu}")
            print("\nBu konulara da gÃ¶z atmanÄ±zÄ± Ã¶neririm.")
        else:
            print("\nTebrikler! TÃ¼m temel konularÄ± Ã¶ÄŸrendiniz.")
        continue
        
    response = qa_chain.run(user_input)
    print("ğŸ¤– Asistan:", response)
    
    for anahtar, konu in konular.items():
        if anahtar in user_input.lower():
            ogrenilen_konular.add(konu)
    
    
