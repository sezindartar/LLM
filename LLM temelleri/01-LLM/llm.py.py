#TASK 1.
#----------------------------------------------------------------------------------------------------------
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
text = "Transformers are amazing!"
tokens = tokenizer.tokenize(text)
token_ids = tokenizer.convert_tokens_to_ids(tokens)

print("Tokens:", tokens)
print("Token IDs:", token_ids)

# Verilen cÃ¼mle 4 adet kÃ¼Ã§Ã¼k dil birimine (token'a) ayrÄ±ldÄ±.
# Her token, modelin anlayabileceÄŸi ÅŸekilde benzersiz sayÄ±sal IDâ€™lere (token IDs) dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼.


#------------------------------------------------------------------------------------------------------------

#TASK 2.
from transformers import pipeline

classifier = pipeline("sentiment-analysis")

print(classifier("The new update made everything so much easier!"))
# [{'label': 'POSITIVE', 'score': 0.9996...}]

print(classifier("I'm confident that I'll master deep learning soon!"))
# [{'label': 'POSITIVE', 'score': 0.9997...}]

print(classifier("This interface is frustrating and hard to use."))
# [{'label': 'NEGATIVE', 'score': 0.9968...}]


#------------------------------------------------------------------------------------------------------------
#TASK 3.

from transformers import pipeline

generator = pipeline("text-generation", model="gpt2")

result = generator("After spending hours exploring neural networks,", max_length=30, temperature=0.9)
print(result[0]['generated_text'])

print("------------------------------------------------------------------------------------------------------------")

result = generator("As the sun rose over the quiet city,", max_length=30, temperature=0.3)
print(result[0]['generated_text'])

print("------------------------------------------------------------------------------------------------------------")

result = generator("I wanted to focus, but my mind kept drifting", max_length=30, temperature=0.7)
print(result[0]['generated_text'])

print("------------------------------------------------------------------------------------------------------------")

# AynÄ± model ayarlarÄ±yla Ã¼Ã§ farklÄ± baÅŸlangÄ±Ã§ cÃ¼mlesi denendi. Her seferinde farklÄ± metinler Ã¼retildi.
# Temperature deÄŸeri 0.7 olduÄŸunda, anlam aÃ§Ä±sÄ±ndan dengeli fakat yer yer belirsiz ifadeler gÃ¶zlendi.
# 0.3 ile denemelerde model daha tutarlÄ± ve sade cÃ¼mleler Ã¼retti, ancak iÃ§erik kÄ±sa ve tekrarlÄ±ydÄ±.
# 0.9 ile denendiÄŸinde ise daha yaratÄ±cÄ±, uzun ve aÃ§Ä±klayÄ±cÄ± cÃ¼mleler Ã¼retildi. Fakat bazen anlam bÃ¼tÃ¼nlÃ¼ÄŸÃ¼ zayÄ±flayabiliyor.
# Temperature deÄŸeri arttÄ±kÃ§a Ã§eÅŸitlilik ve yaratÄ±cÄ±lÄ±k artÄ±yor; azalttÄ±kÃ§a Ã¶ngÃ¶rÃ¼lebilirlik yÃ¼kseliyor, ancak iÃ§erik zayÄ±flÄ±yor.

#------------------------------------------------------------------------------------------------------------
#TASK 4.   
import os
from openai import OpenAI
from dotenv import load_dotenv

# .env dosyasÄ±ndaki API anahtarÄ±nÄ± yÃ¼kle
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Prompt cÃ¼mlesi
prompt = "Bir sabah uyandÄ±ÄŸÄ±nda her ÅŸey deÄŸiÅŸmiÅŸti Ã§Ã¼nkÃ¼ artÄ±k kimse konuÅŸmuyor, herkes sadece bakÄ±ÅŸlarla iletiÅŸim kuruyordu."

# API Ã¼zerinden cevap oluÅŸtur
response = client.chat.completions.create(
    model="gpt-3.5-turbo",  
    messages=[
        {"role": "system", "content": "Sen yaratÄ±cÄ± bir hikaye anlatÄ±cÄ±sÄ±sÄ±n."},
        {"role": "user", "content": prompt}
    ],
    temperature=0.7,
    max_tokens=256,
)

# CevabÄ± yazdÄ±r
print("ğŸš€ Tamamlanan Metin:\n")
print(response.choices[0].message.content)

## Bir sabah uyandÄ±ÄŸÄ±nda her ÅŸey deÄŸiÅŸmiÅŸti Ã§Ã¼nkÃ¼ artÄ±k kimse konuÅŸmuyor, herkes sadece bakÄ±ÅŸlarla iletiÅŸim kuruyordu.
# 
# Tolga, kentin yÃ¼ksek gÃ¼venlikli veri merkezinde gece nÃ¶betindeydi. UyandÄ±ÄŸÄ±nda alarm Ã§almÄ±yordu. MonitÃ¶rler normaldi. Ama... sessizlik anormaldi.
# 
# DÄ±ÅŸarÄ± Ã§Ä±ktÄ±, sokakta insanlar vardÄ± ama bir tuhaflÄ±k vardÄ±: kimse konuÅŸmuyordu.
# 
# GÃ¶z temasÄ±... Herkesin bakÄ±ÅŸlarÄ± adeta bir algoritma gibi Ã§alÄ±ÅŸÄ±yordu. 
# Bir bakÄ±ÅŸ â€“ â€œmerhabaâ€. Uzun bir bakÄ±ÅŸ â€“ â€œtehlike varâ€. Yan bakÄ±ÅŸ â€“ â€œyardÄ±m et.â€
# 
# Tolga, gÃ¼n boyunca tek bir ses bile duymadan analiz yaptÄ±. Sonunda fark etti: 
# dÃ¼n gece ÅŸehir, deneysel bir nÃ¶ral aÄŸ tabanlÄ± iletiÅŸim protokolÃ¼ne geÃ§irilmiÅŸti.
# 
# Ä°nsanlarÄ±n beyin dalgalarÄ±, yapay zeka tarafÄ±ndan algÄ±lanÄ±yor ve doÄŸrudan aktarÄ±lÄ±yordu.
# 
# Ancak sistem hatalÄ±ydÄ±. Duygular kodlara karÄ±ÅŸÄ±yor, dÃ¼ÅŸÃ¼nceler Ã§arpÄ±tÄ±lÄ±yordu.
# 
# Tolgaâ€™nÄ±n son baktÄ±ÄŸÄ± ekranda kÄ±rmÄ±zÄ± bir mesaj belirdi:
# â€œKonuÅŸma yetisini tamamen silmek iÃ§in son 2 dakika.â€
# 
# Ve sonra sistemden bir sinyal geldi. Tolga iÃ§gÃ¼dÃ¼sel olarak dÃ¼ÅŸÃ¼ndÃ¼: â€œHayÄ±r.â€
# Ama sistem, bunu â€œevetâ€ olarak yorumladÄ±...



## SonuÃ§ beni Ã§ok ÅŸaÅŸÄ±rtmadÄ± Ã§Ã¼nkÃ¼ OpenAIâ€™nin dil modelleri, yaratÄ±cÄ± ve anlamlÄ± metin Ã¼retme konusunda oldukÃ§a baÅŸarÄ±lÄ±.
# Belirlenen maksimum kelime sÄ±nÄ±rÄ± nedeniyle Ã¼retilen metin nispeten kÄ±sa kaldÄ±.
# EÄŸer token veya kelime sÄ±nÄ±rÄ± daha yÃ¼ksek ayarlanmÄ±ÅŸ olsaydÄ±, model Ã§ok daha detaylÄ± ve derinlemesine bir hikaye sunabilirdi.
# Bu nedenle, hikayenin potansiyeli tam olarak ortaya Ã§Ä±kmamÄ±ÅŸ olabilir.
